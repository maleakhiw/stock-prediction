{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities\n",
    "\n",
    "**Author**: Maleakhi Agung Wijaya  \n",
    "**Email**: *maw219@cam.ac.uk*  \n",
    "**Description**: This file contains utility functions and constants used in other notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONSTANTS\n",
    "CLASS_NAME = \"MOVEMENT\"\n",
    "DATASET_DJI = \"Datasets/Processed_DJI.csv\"\n",
    "DATASET_NASDAQ = \"Datasets/Processed_NASDAQ.csv\"\n",
    "DATASET_NYSE = \"Datasets/Processed_NYSE.csv\"\n",
    "DATASET_RUSSELL = \"Datasets/Processed_RUSSELL.csv\"\n",
    "DATASET_SP = \"Datasets/Processed_S&P.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_path):\n",
    "    \"\"\"\n",
    "    Load a single dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    df_data = pd.read_csv(file_path, index_col=\"Date\")\n",
    "    \n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_aggregated_datasets(file_paths):\n",
    "    \"\"\"\n",
    "    Load and pre-process datasets from various markets.\n",
    "    \"\"\"\n",
    "    \n",
    "    market_orders = [] # store the order which markets are processed\n",
    "    n_markets = 0 # number of markets used\n",
    "    aggregated_datasets = {}\n",
    "    \n",
    "    # Iterate over different indices data to load and process them\n",
    "    for file_path in file_paths:\n",
    "        df_data = load_dataset(file_path)\n",
    "        \n",
    "        ## Store information on the order of datasets that are processed\n",
    "        data_name = df_data[\"Name\"][0]\n",
    "        market_orders.append(data_name)\n",
    "        del df_data[\"Name\"]\n",
    "        n_markets += 1\n",
    "        \n",
    "        ## Preprocess data\n",
    "        label = (df_data[\"Close\"][1:] / df_data[\"Close\"][:-1].values).astype(int)\n",
    "        df_data = df_data[:-1]\n",
    "        label.index = df_data.index\n",
    "        \n",
    "        # do not use the first 200 data as we use moving average as one of the feature\n",
    "        df_data = df_data[200:]\n",
    "        df_data[CLASS_NAME] = label\n",
    "        \n",
    "        ## Store in dictionary\n",
    "        aggregated_datasets[data_name] = df_data\n",
    "    \n",
    "    return market_orders, n_markets, aggregated_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above code generate vanilla datasets, the following generate\n",
    "# sequential datasets.\n",
    "def generate_sequential_data(df_data, sequence_length):\n",
    "    \"\"\"\n",
    "    Given a dataframe and sequence length, generate sequential data.\n",
    "    \"\"\"\n",
    "    \n",
    "    label = list(df_data[CLASS_NAME])\n",
    "    df_data = df_data.drop(columns=[CLASS_NAME])\n",
    "    sequential_data = [] # used to store sequential data\n",
    "    sequential_target = []\n",
    "    \n",
    "    ## Sequencing data\n",
    "    for idx in range(df_data.shape[0]-sequence_length+1):\n",
    "        sequential_data.append(df_data[idx:idx+sequence_length])\n",
    "        sequential_target.append(label[idx+sequence_length-1])\n",
    "    \n",
    "    ## Notes:\n",
    "    # - If using conv net, add 1 dimension by reshape later.\n",
    "    # - convert the sequential_data list of df to np array later\n",
    "    \n",
    "    return sequential_data, sequential_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above code generate vanilla datasets, the following generate\n",
    "# sequential datasets.\n",
    "def generate_sequential_data_3d(data, target, sequence_length):\n",
    "    \"\"\"\n",
    "    Given a dataframe and sequence length, generate sequential data (for 3d cnn pred).\n",
    "    \"\"\"\n",
    "    sequential_data = []\n",
    "    sequential_target = []\n",
    "    \n",
    "    ## Sequencing data\n",
    "    for idx in range(data.shape[1]-sequence_length+1):\n",
    "        sequential_data.append(data[:, idx:idx+sequence_length])\n",
    "        sequential_target.append(target[idx+sequence_length-1])\n",
    "    \n",
    "    sequential_data = np.array(sequential_data)\n",
    "    sequential_target = np.array(sequential_target)\n",
    "    \n",
    "    return sequential_data, sequential_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_sequential_data(sequence_length, df_datas=None):\n",
    "    \"\"\"\n",
    "    Generate aggregated dataset from all markets.\n",
    "    \"\"\"\n",
    "    \n",
    "    sequential_data = []\n",
    "    sequential_target = []\n",
    "    \n",
    "    # Load datasets\n",
    "    ## If the datasets are not specified, used all datas\n",
    "    if df_datas is None:\n",
    "        market_orders, n_markets, aggregated_datasets = load_aggregated_datasets([DATASET_DJI, \n",
    "                                                                              DATASET_NASDAQ, \n",
    "                                                                              DATASET_NYSE,\n",
    "                                                                              DATASET_RUSSELL, \n",
    "                                                                              DATASET_SP])\n",
    "        \n",
    "        # Iterate over all datasets and generate sequential version of it\n",
    "        for market in market_orders:\n",
    "            seq_data, seq_target = generate_sequential_data(aggregated_datasets[market], sequence_length)\n",
    "            sequential_data.extend(seq_data)\n",
    "            sequential_target.extend(seq_target)\n",
    "            \n",
    "    else:\n",
    "        df_datas = df_datas\n",
    "        \n",
    "        for df_data in df_datas:\n",
    "            seq_data, seq_target = generate_sequential_data(df_data, sequence_length)\n",
    "            sequential_data.extend(seq_data)\n",
    "            sequential_target.extend(seq_target)\n",
    "\n",
    "    \n",
    "    return sequential_data, sequential_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_reshape(X_seq, reshape_size):\n",
    "    \"\"\"\n",
    "    Reshape sequential data into required format.\n",
    "    \"\"\"\n",
    "    \n",
    "    X_seq_new = [X_seq[i].to_numpy() for i in range(len(X_seq))]\n",
    "    X_seq_new = np.array(X_seq_new)\n",
    "    X_seq_new = X_seq_new.reshape(reshape_size)\n",
    "    \n",
    "    return X_seq_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_cv(model, X_train, y_train, cv, scoring):\n",
    "    \"\"\"\n",
    "    Do cross validation and compute relevant statistics.\n",
    "    \"\"\"\n",
    "    \n",
    "    scores = cross_val_score(model, X_train, y_train,\n",
    "                             scoring=scoring, cv=cv)\n",
    "    \n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean Scores:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacking_classifier():\n",
    "    \"\"\"\n",
    "    Create stack classifier.\n",
    "    \"\"\"\n",
    "    \n",
    "    # define the base models\n",
    "    level0 = list()\n",
    "    level0.append(('lr', LogisticRegression()))\n",
    "    level0.append(('knn', KNeighborsClassifier()))\n",
    "    level0.append(('cart', DecisionTreeClassifier()))\n",
    "    level0.append(('svm', SVC()))\n",
    "    level0.append(('bayes', GaussianNB()))\n",
    "\n",
    "    # define meta learner model\n",
    "    level1 = LogisticRegression()\n",
    "\n",
    "    # define the stacking ensemble\n",
    "    model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnnpred_2d(sequence_length, n_feature, n_filters, dropout_rate=0.1):\n",
    "    \"\"\"\n",
    "    Build model using architecture that is specified on the paper\n",
    "    (Hoseinzade and Haratizadeh).\n",
    "    \"\"\"\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        # Layer 1\n",
    "        keras.Input(shape=(sequence_length, n_feature, 1)),\n",
    "        layers.Conv2D(n_filters[0], (1, n_feature), activation=\"relu\"),\n",
    "        \n",
    "        # Layer 2\n",
    "        layers.Conv2D(n_filters[1], (3, 1), activation=\"relu\"),\n",
    "        layers.MaxPool2D(pool_size=(2, 1)),\n",
    "        \n",
    "        # Layer 3\n",
    "        layers.Conv2D(n_filters[2], (3, 1), activation=\"relu\"),\n",
    "        layers.MaxPool2D(pool_size=(2, 1)),\n",
    "        \n",
    "        # FFNN\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnnpred_3d(n_markets, sequence_length, n_feature, n_filters):\n",
    "    \"\"\"\n",
    "    Build model using architecture that is specified on the paper\n",
    "    (Hoseinzade and Haratizadeh).\n",
    "    \"\"\"\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        # layer 1\n",
    "        layers.Conv2D(n_filters[0], (1, 1), activation='relu', \n",
    "                      input_shape=(n_markets,sequence_length,n_feature), data_format='channels_last'),\n",
    "        \n",
    "        # layer 2\n",
    "        layers.Conv2D(n_filters[1], (n_markets, 3), activation=\"relu\"),\n",
    "        layers.MaxPool2D(pool_size=(1, 2)),\n",
    "        \n",
    "        # layer 3\n",
    "        layers.Conv2D(n_filters[2], (1, 3), activation=\"relu\"),\n",
    "        layers.MaxPool2D(pool_size=(1, 2)),\n",
    "        \n",
    "        # FFNN\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(win_length, num_features):\n",
    "    \"\"\"\n",
    "    Build LSTM model for predicting stock market direction.\n",
    "    \"\"\"\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.LSTM(128, input_shape=(win_length, num_features), return_sequences=True))\n",
    "    model.add(layers.LeakyReLU(alpha=0.5))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.LSTM(64, return_sequences=False))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision_pos = precision(y_true, y_pred)\n",
    "    recall_pos = recall(y_true, y_pred)\n",
    "    precision_neg = precision((K.ones_like(y_true) - y_true), (K.ones_like(y_pred) - K.clip(y_pred, 0, 1)))\n",
    "    recall_neg = recall((K.ones_like(y_true) - y_true), (K.ones_like(y_pred) - K.clip(y_pred, 0, 1)))\n",
    "    f_posit = 2 * ((precision_pos * recall_pos) / (precision_pos + recall_pos + K.epsilon()))\n",
    "    f_neg = 2 * ((precision_neg * recall_neg) / (precision_neg + recall_neg + K.epsilon()))\n",
    "\n",
    "    return (f_posit + f_neg) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_test, y_predict, labels, cmap=\"Blues\"):\n",
    "    # Plot confusion matrix and normalised confusion matrix\n",
    "    fig1 = plt.figure(figsize=(4,4))\n",
    "    fig2 = plt.figure(figsize=(4,4))\n",
    "    ax1 = fig1.add_subplot(111)\n",
    "    ax2 = fig2.add_subplot(111)\n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "    disp = ConfusionMatrixDisplay(cm)\n",
    "    disp = disp.plot(ax=ax1, cmap=cmap)\n",
    "    cm_n = confusion_matrix(y_test, y_predict, normalize=\"true\")\n",
    "    disp_n = ConfusionMatrixDisplay(cm_n)\n",
    "    disp_n = disp_n.plot(ax=ax2, cmap=cmap)\n",
    "            \n",
    "    ax1.set_xticklabels(labels)\n",
    "    ax1.set_yticklabels(labels, rotation=90)\n",
    "    ax2.set_xticklabels(labels)\n",
    "    ax2.set_yticklabels(labels, rotation=90)\n",
    "    ax1.set_xlabel(\"$Predicted$\")\n",
    "    ax2.set_xlabel(\"$Predicted$\")\n",
    "    ax1.set_ylabel(\"$True$\")\n",
    "    ax2.set_ylabel(\"$True$\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pr_vs_threshold(precisions, recalls, thresholds):\n",
    "    \"\"\"\n",
    "    Plot precision and recall against threshold.\n",
    "    \"\"\"\n",
    "    \n",
    "    fig = plt.figure(figsize=(6,4))\n",
    "    ax = plt.subplot2grid((1,1), (0,0))\n",
    "    ax.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "    ax.plot(thresholds, recalls[:-1], \"g--\", label=\"Recall\")\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.ylim([0, 1])\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    \"\"\"\n",
    "    Plot roc curve.\n",
    "    \"\"\"\n",
    "    \n",
    "    fig = plt.figure(figsize=(6,4))\n",
    "    ax = plt.subplot2grid((1,1), (0,0))\n",
    "    ax.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    ax.plot([0, 1], [0, 1], \"k--\")\n",
    "    ax.axis([0, 1, 0, 1.01])\n",
    "    plt.xlabel(\"False positive rate (fpr)\")\n",
    "    plt.ylabel(\"True positive rate (tpr)\")\n",
    "    \n",
    "    return ax"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
